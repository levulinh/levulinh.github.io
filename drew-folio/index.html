<!DOCTYPE html>
<html lang="en">

  <!-- Head -->
  <head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">    <!-- Metadata, OpenGraph and Schema.org -->
    

    <!-- Standard metadata -->
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <title>portfolio | MT_Box</title>
    <meta name="author" content="Andrew V. Le">
    <meta name="description" content="Look what I have done!">
    <meta name="keywords" content="jekyll, jekyll-theme, academic-website, portfolio-website">


    <!-- Bootstrap & MDB -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous">

    <!-- Bootstrap Table -->
    <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.css">

    <!-- Fonts & Icons -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous">
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons">

    <!-- Code Syntax Highlighting -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light">

    

    <!-- Styles -->
    
    <link rel="shortcut icon" href="/assets/img/fav.png">
    
    <link rel="stylesheet" href="/assets/css/main.css">
    <link rel="canonical" href="https://levulinh.github.io/drew-folio/">

    <!-- Dark Mode -->
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark">

    <script src="/assets/js/theme.js"></script>
    <script src="/assets/js/dark_mode.js"></script>
    

  </head>

  <!-- Body -->
  <body class="fixed-top-nav ">

    <!-- Header -->
    <header>

      <!-- Nav Bar -->
      <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top">
        <div class="container">
          <a class="navbar-brand title font-weight-lighter" href="/">MT_Box</a>
          <!-- Navbar Toggle -->
          <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
            <span class="sr-only">Toggle navigation</span>
            <span class="icon-bar top-bar"></span>
            <span class="icon-bar middle-bar"></span>
            <span class="icon-bar bottom-bar"></span>
          </button>

          <div class="collapse navbar-collapse text-right" id="navbarNav">
            <ul class="navbar-nav ml-auto flex-nowrap">

              <!-- About -->
              <li class="nav-item ">
                <a class="nav-link" href="/">about</a>
              </li>
              
              <!-- Blog -->
              <li class="nav-item ">
                <a class="nav-link" href="/blog/">blog</a>
              </li>

              <!-- Other pages -->
              <li class="nav-item ">
                <a class="nav-link" href="/publications/">publications</a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/albums/">albums</a>
              </li>
              <li class="nav-item active">
                <a class="nav-link" href="/drew-folio/">portfolio<span class="sr-only">(current)</span></a>
              </li>
              <li class="nav-item ">
                <a class="nav-link" href="/cv/">cv</a>
              </li>

              <!-- Toogle theme mode -->
              <li class="toggle-container">
                <button id="light-toggle" title="Change theme">
                  <i class="fas fa-moon"></i>
                  <i class="fas fa-sun"></i>
                </button>
              </li>
            </ul>
          </div>
        </div>
      </nav>

      <!-- Scrolling Progress Bar -->
      <progress id="progress" value="0">
        <div class="progress-container">
          <span class="progress-bar"></span>
        </div>
      </progress>
    </header>


    <!-- Content -->
    <div class="container mt-5">
      
        <!-- page.html -->
        <div class="post">

          <header class="post-header">
            <h1 class="post-title">portfolio</h1>
            <p class="post-description">Look what I have done!</p>
          </header>

          <article>
            <h2 id="project-0-dynamic-graph-convolutional-neural-network-for-image-classification-on-superpixel-images">Project 0: Dynamic Graph Convolutional Neural Network for Image Classification on superpixel images</h2>

<p>This is my first publication during my master‚Äôs degree (Hence the number 0). Despite of a very rushing deadline, I managed to pull it off, and I am proud of it. The project was about using a dynamic graph convolutional neural network to classify superpixel images. The model was trained on multiple datasets, including CIFAR, Fashion-MNIST, superpixel-MNIST. And the superpixel images were generated using the <a href="https://scikit-image.org/docs/dev/auto_examples/segmentation/plot_segmentations.html" rel="external nofollow noopener" target="_blank">SLIC</a> algorithm.</p>

<p>In this project, I proposed a new method to generate graphs on superpixel images dynamically every iteration, mitigating
the problem of graph saturation, and increasing the receptive field of the model. The method out-performed the SOTA methods on the same setting on multiple datasets.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/dynamic_gnn-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/dynamic_gnn-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/dynamic_gnn-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/dynamic_gnn.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>

<p>Perfomance comparison:</p>

<ul>
  <li>on MNIST-75</li>
</ul>

<table>
  <thead>
    <tr>
      <th>¬†</th>
      <th>MNIST-75</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>MoNET</td>
      <td>91.11%</td>
    </tr>
    <tr>
      <td>SplineCNN</td>
      <td>95.22%</td>
    </tr>
    <tr>
      <td>GeoGCN</td>
      <td>95.95%</td>
    </tr>
    <tr>
      <td>RAG-GAT</td>
      <td>96.19%</td>
    </tr>
    <tr>
      <td><strong>Ours</strong></td>
      <td><strong>99.04%</strong></td>
    </tr>
  </tbody>
</table>

<ul>
  <li>on Fashion-MNIST</li>
</ul>

<table>
  <thead>
    <tr>
      <th>¬†</th>
      <th>Fashion-MNIST</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>RAG-GAT</td>
      <td>83.07%</td>
    </tr>
    <tr>
      <td><strong>Ours</strong></td>
      <td><strong>90.02%</strong></td>
    </tr>
  </tbody>
</table>

<h3 id="pulication">Pulication:</h3>
<p><a href="https://ieeexplore.ieee.org/abstract/document/9621101" rel="external nofollow noopener" target="_blank">Dynamic Graph Neural Network for Super-Pixel Image Classification</a></p>

<h3 id="technologies-used">Technologies Used:</h3>
<ul>
  <li>PyTorch</li>
  <li>PyTorch Geometric</li>
  <li>SLIC</li>
</ul>

<h3 id="repository">Repository:</h3>
<p>A repository of a similar project that I did for remote sensing data, the technique is the same, but the data are
real-word data.</p>

<div class="repo p-2 text-center">
  <a href="https://github.com/levulinh/remote-sensing-dynamic-spixel" rel="external nofollow noopener" target="_blank">
    <img class="repo-img-light w-100" alt="levulinh/remote-sensing-dynamic-spixel" src="https://github-readme-stats.vercel.app/api/pin/?username=levulinh&amp;repo=remote-sensing-dynamic-spixel&amp;theme=default&amp;show_owner=false">
    <img class="repo-img-dark w-100" alt="levulinh/remote-sensing-dynamic-spixel" src="https://github-readme-stats.vercel.app/api/pin/?username=levulinh&amp;repo=remote-sensing-dynamic-spixel&amp;theme=dark&amp;show_owner=false">
  </a>
</div>

<hr>

<h2 id="project-1-multi-task-distillation-learning-for-image">Project 1: Multi-task Distillation learning for Image</h2>

<p>Context: So, let‚Äôs rewind a bit and talk about the sleep monitoring gig at Asleep. We decided to spice things up by throwing Vision Transformer (ViT) models into the mix. Forget the typical Recurrent Neural Network (RNN) routine ‚Äì we took a different route, predicting sleep stages, catching apnea events, and eavesdropping on snores using ViT models. The twist? We didn‚Äôt just toss raw data at our AI; we served it up with transformed Mel-spectrograms of breathing sounds. Why ViT? Picture a sleep detective that hones in on the nitty-gritty details in those spectrograms, making our predictions spot-on. No shade to the RNN crew, but ViT not only steals the spotlight but does it in real-time fashion. It‚Äôs been a thrilling journey, and we‚Äôre rewriting the playbook on sleep monitoring ‚Äì one ViT model at a time!</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/sound_to_mel-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/sound_to_mel-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/sound_to_mel-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/sound_to_mel.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/two_stage-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/two_stage-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/two_stage-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/two_stage.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    The overall architecture of our sound-based models. For more information, please refer to the ICLR <a href="https://openreview.net/pdf?id=mIRztWMsVJ" rel="external nofollow noopener" target="_blank">Workshop paper</a>.
</div>

<h3 id="then-whats-the-problem">Then what‚Äôs the problem?</h3>
<ul>
  <li>
    <p><strong>Task Segregation Woes:</strong>
Although our sleep monitoring tasks appeared closely related, they were operating in separate spheres, leading to a missed opportunity for potential performance and speed enhancement.</p>
  </li>
  <li>
    <p><strong>Multi-Task Model Dilemma:</strong>
Building a multi-task model seemed like the logical next step, but the real challenge lay in the intricacies of training. Integrating tasks might sound easy, but figuring out the most effective training strategy proved to be a different story altogether.</p>
  </li>
  <li>
    <p><strong>The Naive Approach Pitfall:</strong>
In attempting to streamline our efforts, we naively opted for training the model with supervised learning. However, the outcome was far from ideal ‚Äì the performance of at least one task took a nosedive, a twist we hadn‚Äôt quite anticipated. Stick around as I unravel the complexities and showcase the unexpected hurdles in achieving seamless integration.</p>
  </li>
</ul>

<h3 id="the-solution-multi-task-distillation-learning">The Solution: Multi-Task Distillation Learning</h3>

<ul>
  <li>
<strong>The Big Picture:</strong>
You can‚Äôt expect both (or more) tasks to keep the same performance by only training them supervisedly, and simultaneously. The solution is to train the model with a combination of supervised and distillation learning. The supervised learning part is to keep the performance of each task, and the distillation learning part is to make the model learn from other tasks, which is the key to the whole thing.</li>
</ul>

<p>The whole idea is inspired by the paper <a href="https://arxiv.org/abs/2007.06889" rel="external nofollow noopener" target="_blank">Knowledge Distillation for Multi-task Learning</a>.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/multi_head-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/multi_head-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/multi_head-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/multi_head.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Overall architecture of the multi-task model.
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/multi_head_train-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/multi_head_train-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/multi_head_train-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/multi_head_train.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Oversimplified training process of the multi-task model.
</div>

<p>But, there is one more thing. The method proposed by the paper did not take into account the difficulty of adapting to the new tasks from the same root. So, I made a modification to the method, and it worked like a charm.
I moved the distillation loss to the beginning of the split heads, so that the model can adapt the changes in the new tasks faster.</p>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/multi_head_train_2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/multi_head_train_2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/multi_head_train_2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/multi_head_train_2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>

<p>Due to the limitation of what I can expose, the only thing that I can provide is the performance of the model on the test set of all tasks surpasses the performance of the model trained with supervised learning only, and separately.</p>

<h3 id="publications">Publications:</h3>
<ul>
  <li><a href="https://www.jmir.org/2023/1/e44818/" rel="external nofollow noopener" target="_blank">Real-Time Detection of Sleep Apnea Based on Breathing Sounds and Prediction Reinforcement Using Home Noises: Algorithm Development and Validation</a></li>
  <li><a href="https://jamanetwork.com/journals/jamaotolaryngology/article-abstract/2812069" rel="external nofollow noopener" target="_blank">In-Home Smartphone-Based Prediction of Obstructive Sleep Apnea in Conjunction With Level 2 Home Polysomnography</a></li>
  <li><a href="https://journal.chestnet.org/article/S0012-3692(23)05087-0/fulltext" rel="external nofollow noopener" target="_blank">EVALUATION OF A SOUND-BASED DEEP LEARNING MODEL FOR HOME-BASED OBSTRUCTIVE SLEEP APNEA DETECTION USING LEVEL 2 HOME PSG DATA</a></li>
</ul>

<h3 id="technologies-used-1">Technologies Used:</h3>

<ul>
  <li>PyTorch</li>
</ul>

<hr>

<h2 id="project-2-dog-breed-image-and-news-text-classification">Project 2: Dog Breed (image) and News (text) Classification</h2>

<p>This is the client for my two projects that I did in a course of my early year in master‚Äôs degree. The project contains two small fun apps:</p>
<ul>
  <li>News classification: This app is used to classify news into 4 categories: business, entertainment, politics, sport and tech.</li>
  <li>Dog breed classification: This app is used to classify dog breeds into 120 breeds.</li>
</ul>

<p>The models were rather simple, but for a first year master‚Äôs student, it was a good start. The models were trained using PyTorch and deployed using Flask. The client was built using ReactJS.</p>

<p>After years, I can definitely see a lot of things that I could have done better. But it was a good start, and I am proud of it.</p>

<h3 id="model-architecture">Model Architecture:</h3>
<ul>
  <li>News classification: An SetimentRNN model with 3 layers of LSTM. Using GloVe embedding, and <code class="language-plaintext highlighter-rouge">simple-english</code> tokenizer. Trained with BBC News dataset.</li>
  <li>Dog breed classification: A simple CNN model with 4 convolutional layers and 2 fully connected layers. Trained on a dataset of 120 dog breeds.</li>
</ul>

<p>Both datasets were downloaded from Kaggle. And the models were trained on Google Colab (I know, I was a poor student back then üòÅ).</p>

<h3 id="screenshots">Screenshots:</h3>

<p>Dog breed classification</p>
<div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/dog_breed-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/dog_breed-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/dog_breed-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/dog_breed.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="dog breed clf" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/dog_breed_2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/dog_breed_2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/dog_breed_2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/dog_breed_2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>

<p>News classification</p>
<div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/news_clf-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/news_clf-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/news_clf-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/news_clf.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="dog breed clf" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/news_clf_2-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/news_clf_2-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/news_clf_2-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/news_clf_2.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>

<h3 id="tools-used">Tools Used:</h3>

<ul>
  <li>PyTorch</li>
  <li>Flask</li>
  <li>ReactJS</li>
</ul>

<h3 id="link-to-project">Link to Project:</h3>
<p>The client is deployed on Render, and can be accessed here:</p>
<ul>
  <li><a href="https://what-the-dog.onrender.com" rel="external nofollow noopener" target="_blank">Project Demo</a></li>
</ul>

<div class="repo p-2 text-center">
  <a href="https://github.com/levulinh/SOC-Term-project-client" rel="external nofollow noopener" target="_blank">
    <img class="repo-img-light w-100" alt="levulinh/SOC-Term-project-client" src="https://github-readme-stats.vercel.app/api/pin/?username=levulinh&amp;repo=SOC-Term-project-client&amp;theme=default&amp;show_owner=false">
    <img class="repo-img-dark w-100" alt="levulinh/SOC-Term-project-client" src="https://github-readme-stats.vercel.app/api/pin/?username=levulinh&amp;repo=SOC-Term-project-client&amp;theme=dark&amp;show_owner=false">
  </a>
</div>

<p>But the server is not deployed, due to the limit of free tier on Render. If you want to see the server, you can clone the repo and run it locally.</p>

<div class="repo p-2 text-center">
  <a href="https://github.com/levulinh/SOC-Term-project-server" rel="external nofollow noopener" target="_blank">
    <img class="repo-img-light w-100" alt="levulinh/SOC-Term-project-server" src="https://github-readme-stats.vercel.app/api/pin/?username=levulinh&amp;repo=SOC-Term-project-server&amp;theme=default&amp;show_owner=false">
    <img class="repo-img-dark w-100" alt="levulinh/SOC-Term-project-server" src="https://github-readme-stats.vercel.app/api/pin/?username=levulinh&amp;repo=SOC-Term-project-server&amp;theme=dark&amp;show_owner=false">
  </a>
</div>

<hr>

<h2 id="project-3-the-flutter-vocab-learning-app-wip">Project 3: The Flutter Vocab learning App (WIP)</h2>
<p>This is a WIP project that I have been working on for a while. It is a simple app that helps you learn new vocabularies in a foreign language in a fun way. I am building it with Flutter, and it so far has been an exciting journey. I am still working on it, and I hope to finish it soon.</p>

<h3 id="screenshots-1">Screenshots:</h3>
<div class="row justify-content-sm-center">
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/voca_start-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/voca_start-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/voca_start-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/voca_start.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/voca_home-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/voca_home-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/voca_home-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/voca_home.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>

<div class="row justify-content-sm-center">
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/voca_remember-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/voca_remember-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/voca_remember-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/voca_remember.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/voca_forget-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/voca_forget-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/voca_forget-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/voca_forget.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
    <div class="col-sm-4 mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/voca_detail-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/voca_detail-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/voca_detail-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/voca_detail.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Screenshots of the application (WIP).
</div>

<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/openai_finetune-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/openai_finetune-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/openai_finetune-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/openai_finetune.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>
<div class="caption">
    Model finetuning with OpenAI's GPT-3.5.
</div>

<h3 id="technologies-used-2">Technologies Used:</h3>
<ul>
  <li>Flutter</li>
  <li>Dart</li>
  <li>OpenAI API</li>
</ul>

<hr>

<h2 id="project-4-kings-beat---the-game-">Project 4: King‚Äôs beat - the game üëæ</h2>

<p>Did I say I am so so so into games? üéÆ Playing them, making them, even this page‚Äôs favicon is a game icon. This is a project that I tried a few months ago, just to try out the Godot game engine. It was a fun experience, and I learned a lot about game development.</p>

<h3 id="free-assets-used">Free assets used</h3>
<ul>
  <li><a href="https://pixelfrog-assets.itch.io/kings-and-pigs" rel="external nofollow noopener" target="_blank">Kings and pigs</a></li>
</ul>

<h3 id="what-did-i-build">What did I build?</h3>
<ul>
  <li>A simple map from tilesets</li>
  <li>I drew the little score bar with Procreate</li>
  <li>Game logic that resembles the original game <code class="language-plaintext highlighter-rouge">Audition</code> (the legendary game that I played a lot when I was a kid)</li>
  <li>Scoring system</li>
</ul>

<h3 id="screenshots-2">Screenshots:</h3>
<div class="row mt-3">
    <div class="col-sm mt-3 mt-md-0">
        <figure>

  <picture>
    
    <source class="responsive-img-srcset" media="(max-width: 480px)" srcset="/assets/img/portfolio/king_beat-480.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 800px)" srcset="/assets/img/portfolio/king_beat-800.webp"></source>
    <source class="responsive-img-srcset" media="(max-width: 1400px)" srcset="/assets/img/portfolio/king_beat-1400.webp"></source>
    

    <!-- Fallback to the original file -->
    <img src="/assets/img/portfolio/king_beat.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" data-zoomable="" onerror="this.onerror=null; $('.responsive-img-srcset').remove();">

  </picture>

</figure>

    </div>
</div>

<iframe width="100%" height="auto" src="https://www.youtube.com/embed/DeB7pYBUbDo" title="King beat demo video" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe>

<p>And more on the github repo.</p>

<h3 id="technologies-used-3">Technologies Used:</h3>

<ul>
  <li>Godot 4.0</li>
  <li>GDScript</li>
</ul>

<h3 id="link-to-project-1">Link to Project:</h3>

<div class="repo p-2 text-center">
  <a href="https://github.com/levulinh/king-beat-game" rel="external nofollow noopener" target="_blank">
    <img class="repo-img-light w-100" alt="levulinh/king-beat-game" src="https://github-readme-stats.vercel.app/api/pin/?username=levulinh&amp;repo=king-beat-game&amp;theme=default&amp;show_owner=false">
    <img class="repo-img-dark w-100" alt="levulinh/king-beat-game" src="https://github-readme-stats.vercel.app/api/pin/?username=levulinh&amp;repo=king-beat-game&amp;theme=dark&amp;show_owner=false">
  </a>
</div>

<hr>

<h2 id="contact-me">Contact Me</h2>

<ul>
  <li>Email: levulinhkr@gmail.com</li>
  <li>LinkedIn: <a href="https://www.linkedin.com/in/andrew-le-d28m08y19/" rel="external nofollow noopener" target="_blank">Andrew Le</a>
</li>
  <li>GitHub: <a href="https://github.com/levulinh" rel="external nofollow noopener" target="_blank">Le Vu Linh</a>
</li>
</ul>

          </article>

        </div>

      
    </div>

    <!-- Footer -->    
    <footer class="fixed-bottom">
      <div class="container mt-0">
        ¬© Copyright 2024 Andrew V. Le. Last updated: February 14, 2024.
      </div>
    </footer>

    <!-- JavaScripts -->
    <!-- jQuery -->
  <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script>

    <!-- Bootsrap & MDB scripts -->
  <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script>
  <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script>

    <!-- Masonry & imagesLoaded -->
  <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script>
  <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script>
  <script defer src="/assets/js/masonry.js" type="text/javascript"></script>
    
  <!-- Medium Zoom JS -->
  <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script>
  <script defer src="/assets/js/zoom.js"></script>

  <!-- Bootstrap Table -->
  <script defer src="https://unpkg.com/bootstrap-table@1.21.3/dist/bootstrap-table.min.js"></script>

  <!-- Load Common JS -->
  <script src="/assets/js/no_defer.js"></script>
  <script defer src="/assets/js/common.js"></script>
  <script defer src="/assets/js/copy_code.js" type="text/javascript"></script>

    
  <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script>
  <script async src="https://badge.dimensions.ai/badge.js"></script>

    <!-- MathJax -->
  <script type="text/javascript">
    window.MathJax = {
      tex: {
        tags: 'ams'
      }
    };
  </script>
  <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script>
  <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>

    
    

<!-- Scrolling Progress Bar -->
<script type="text/javascript">
  /*
   * This JavaScript code has been adapted from the article 
   * https://css-tricks.com/reading-position-indicator/ authored by Pankaj Parashar, 
   * published on the website https://css-tricks.com on the 7th of May, 2014.
   * Couple of changes were made to the original code to make it compatible 
   * with the `al-foio` theme.
   */
  const progressBar = $("#progress");
  /*
   * We set up the bar after all elements are done loading.
   * In some cases, if the images in the page are larger than the intended
   * size they'll have on the page, they'll be resized via CSS to accomodate
   * the desired size. This mistake, however, breaks the computations as the
   * scroll size is computed as soon as the elements finish loading.
   * To account for this, a minimal delay was introduced before computing the
   * values.
   */
  window.onload = function () {
    setTimeout(progressBarSetup, 50);
  };
  /*
   * We set up the bar according to the browser.
   * If the browser supports the progress element we use that.
   * Otherwise, we resize the bar thru CSS styling
   */
  function progressBarSetup() {
    if ("max" in document.createElement("progress")) {
      initializeProgressElement();
      $(document).on("scroll", function() {
        progressBar.attr({ value: getCurrentScrollPosition() });
      });
      $(window).on("resize", initializeProgressElement);
    } else {
      resizeProgressBar();
      $(document).on("scroll", resizeProgressBar);
      $(window).on("resize", resizeProgressBar);
    }
  }
  /*
   * The vertical scroll position is the same as the number of pixels that
   * are hidden from view above the scrollable area. Thus, a value > 0 is
   * how much the user has scrolled from the top
   */
  function getCurrentScrollPosition() {
    return $(window).scrollTop();
  }

  function initializeProgressElement() {
    let navbarHeight = $("#navbar").outerHeight(true);
    $("body").css({ "padding-top": navbarHeight });
    $("progress-container").css({ "padding-top": navbarHeight });
    progressBar.css({ top: navbarHeight });
    progressBar.attr({
      max: getDistanceToScroll(),
      value: getCurrentScrollPosition(),
    });
  }
  /*
   * The offset between the html document height and the browser viewport
   * height will be greater than zero if vertical scroll is possible.
   * This is the distance the user can scroll
   */
  function getDistanceToScroll() {
    return $(document).height() - $(window).height();
  }

  function resizeProgressBar() {
    progressBar.css({ width: getWidthPercentage() + "%" });
  }
  // The scroll ratio equals the percentage to resize the bar
  function getWidthPercentage() {
    return (getCurrentScrollPosition() / getDistanceToScroll()) * 100;
  }
</script>

  </body>
</html>
